package io.kafkaobs.substrates;

import io.kafkaobs.shared.models.MonitorSignal;
import io.humainary.modules.serventis.monitors.api.Monitors;
import io.kafkaobs.shared.models.ReporterSignal;
import io.humainary.modules.serventis.reporters.api.Reporters;
import io.kafkaobs.substrates.aggregators.health.ClusterHealthAggregator;
import io.kafkaobs.substrates.sink.Capture;
import io.kafkaobs.substrates.sink.Sink;
import io.kafkaobs.substrates.sink.SinkQuery;
import org.junit.jupiter.api.Disabled;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;

import java.time.Duration;
import java.time.Instant;
import java.util.List;
import java.util.Optional;

import org.springframework.test.annotation.DirtiesContext;
import org.springframework.test.annotation.DirtiesContext.ClassMode;

import static java.util.concurrent.TimeUnit.SECONDS;
import static org.assertj.core.api.Assertions.assertThat;
import static org.awaitility.Awaitility.await;

/**
 * Integration test for kafka.situations circuit end-to-end flow.
 *
 * <p>Tests the complete flow: broker failure → ClusterHealthAggregator → ReporterSignal emission.
 *
 * TODO Story 4.3: Re-enable when drain() streaming API replaces query()
 */
@Disabled("Disabled pending Story 4.3 - query() method removed, drain() streaming API not yet implemented")
@SpringBootTest
@DirtiesContext(classMode = ClassMode.BEFORE_EACH_TEST_METHOD)
class SituationsCircuitIntegrationTest {

    @Autowired
    private CortexRuntime cortex;

    @Autowired
    private ClusterHealthAggregator clusterHealthAggregator;

    @Test
    void shouldEmitClusterSituationOnBrokerFailure() {
        // Given - Use unique broker IDs to avoid test pollution
        String testId = "failure-" + System.currentTimeMillis();

        // Given - Simulate 5 brokers, 3 will fail (60% > 50% threshold)
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-001", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-002", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-003", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-004", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-005", Monitors.Condition.STABLE);

        // Small delay to let initial emissions settle
        try { Thread.sleep(100); } catch (InterruptedException e) {}

        // When - 3 brokers go down (60% > 50% threshold → CRITICAL)
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-001", Monitors.Condition.DOWN);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-002", Monitors.Condition.DOWN);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-003", Monitors.Condition.DOWN);

        // Then - CRITICAL ReporterSignal emitted to kafka.situations
        await().atMost(30, SECONDS).untilAsserted(() -> {
            List<Capture> situations = querySituations();

            assertThat(situations)
                .as("Should have at least one situation signal")
                .isNotEmpty();

            assertThat(situations)
                .anySatisfy(capture -> {
                    assertThat(capture.value()).isEqualTo("CRITICAL");
                    assertThat(capture.subject()).isEqualTo("cluster.situation");

                    // Verify metadata conventions
                    assertThat(capture.metadata())
                        .containsEntry("source", "ClusterHealthAggregator")
                        .containsEntry("pattern", "cluster-degradation")
                        .containsEntry("totalBrokers", "5")
                        .containsEntry("downBrokers", "3");

                    // Verify affectedResources includes failed brokers
                    String affectedResources = capture.metadata().get("affectedResources");
                    assertThat(affectedResources)
                        .contains("broker-001")
                        .contains("broker-002")
                        .contains("broker-003");
                });
        });
    }

    @Test
    void shouldEmitWarningWhenClusterDegraded() {
        // Given - Use unique broker IDs to avoid test pollution
        String testId = "warning-" + System.currentTimeMillis();

        // Given - 3 brokers, 1 will be degraded (33% = degradation threshold)
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-001", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-002", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-003", Monitors.Condition.STABLE);

        // Small delay to let initial emissions settle
        try { Thread.sleep(100); } catch (InterruptedException e) {}

        // When - 1 broker degrades (33% = threshold → DEGRADED → WARNING)
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-001", Monitors.Condition.DEGRADED);

        // Then - WARNING ReporterSignal emitted
        await().atMost(30, SECONDS).untilAsserted(() -> {
            List<Capture> situations = querySituations();

            assertThat(situations)
                .anySatisfy(capture -> {
                    assertThat(capture.value()).isEqualTo("WARNING");
                    assertThat(capture.subject()).isEqualTo("cluster.situation");
                    assertThat(capture.metadata())
                        .containsEntry("source", "ClusterHealthAggregator")
                        .containsEntry("pattern", "cluster-degradation")
                        .containsEntry("degradedBrokers", "1");
                });
        });
    }

    @Test
    void shouldEmitBothMonitorAndReporterSignals() {
        // Given - Use unique broker IDs to avoid test pollution
        String testId = "both-" + System.currentTimeMillis();

        // Given - Fresh brokers
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-test-1", Monitors.Condition.STABLE);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-test-2", Monitors.Condition.STABLE);

        // Small delay to let initial emissions settle
        try { Thread.sleep(100); } catch (InterruptedException e) {}

        // When - Majority fail
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-test-1", Monitors.Condition.DOWN);
        clusterHealthAggregator.updateBrokerStatus(testId + "-broker-test-2", Monitors.Condition.DOWN);

        // Then - Both MonitorSignal (to cluster.coordination) and ReporterSignal (to situations) emitted
        await().atMost(30, SECONDS).untilAsserted(() -> {
            // Check MonitorSignal
            List<Capture> monitorSignals = queryMonitorSignals();
            assertThat(monitorSignals)
                .anySatisfy(capture -> {
                    assertThat(capture.subject()).isEqualTo("cluster.status");
                    assertThat(capture.value()).isEqualTo("DOWN");
                });

            // Check ReporterSignal
            List<Capture> reporterSignals = querySituations();
            assertThat(reporterSignals)
                .anySatisfy(capture -> {
                    assertThat(capture.subject()).isEqualTo("cluster.situation");
                    assertThat(capture.value()).isEqualTo("CRITICAL");
                });
        });
    }

    /**
     * Query ReporterSignals from kafka.situations circuit.
     */
    private List<Capture> querySituations() {
        SinkQuery query = new SinkQuery(
            Optional.of(Instant.now().minus(Duration.ofMinutes(5))),
            Optional.of(Instant.now()),
            Optional.of("cluster.situation"),
            Optional.of("ReporterSignal")
        );
        return cortex.getSink().query(query);
    }

    /**
     * Query MonitorSignals from kafka.cluster.coordination circuit.
     */
    private List<Capture> queryMonitorSignals() {
        SinkQuery query = new SinkQuery(
            Optional.of(Instant.now().minus(Duration.ofMinutes(5))),
            Optional.of(Instant.now()),
            Optional.of("cluster.status"),
            Optional.of("MonitorSignal")
        );
        return cortex.getSink().query(query);
    }
}
